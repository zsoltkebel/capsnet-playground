<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <title>TensorFlow.js browser example</title>

    <!-- Load TensorFlow.js from a script tag -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  </head>
  <body>
    <h1>TensorFlow.js example</h1>
    <h2>Open the console to see the results.</h2>
    <div class="container">
      <h1>GeeksForGeeks</h1>
      <h4>Using createElement</h4>
      <button onclick="addCapsule([0, 1, 2])">
          Add New Element</button>
    </div>
    <script>
    // Define a model for linear regression. The script tag makes `tf` available
    // as a global variable.
    const model = tf.sequential();
    model.add(tf.layers.dense({units: 1, inputShape: [1]}));

    model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});

    // Generate some synthetic data for training.
    const xs = tf.tensor2d([1, 2, 3, 4], [4, 1]);
    const ys = tf.tensor2d([1, 3, 5, 7], [4, 1]);

    // Train the model using the data.
    model.fit(xs, ys, {epochs: 10}).then(() => {
      // Use the model to do inference on a data point the model hasn't seen before:
      model.predict(tf.tensor2d([5], [1, 1])).print();
      // Open the browser devtools to see the output
    });


    function routing(in_capsules, out_capsule_count, out_capsule_dimension, r=3) {
      let in_capsule_count = 3;
      let in_capsule_dimension = 2;

      // const W = tf.randomNormal([1, in_capsule_count, out_capsule_count, out_capsule_dimension, in_capsule_dimension]);

      const W = tf.tensor([[[[[-0.2720, -0.3906],
           [ 0.6187,  0.4854]],

          [[ 1.3667, -0.2222],
           [ 0.8012,  2.1180]]],


         [[[ 0.0833, -0.2355],
           [ 1.2901, -0.9415]],

          [[ 0.6626,  0.7623],
           [ 0.7971, -1.1760]]],


         [[[-1.6190, -0.8066],
           [ 1.1043, -0.8219]],

          [[ 0.5557, -0.3481],
           [ 0.0916,  1.0921]]]]])

      console.log("W");
      W.print();
      
      let b_ij = tf.zeros([in_capsule_count, out_capsule_count]);
      console.log("b_ij");
      b_ij.print();

      let u = in_capsules
        .expandDims(1)
        .broadcastTo([in_capsule_count, out_capsule_count, in_capsule_dimension])
        .expandDims(3);
      console.log("u");
      u.print();

      let u_hat = tf.matMul(W, u);
      // u_hat.squeeze(3);
      console.log("u_hat:");
      u_hat.print();
      u_hat = u_hat.reshape([in_capsule_count, out_capsule_count, in_capsule_dimension]);
      console.log("u_hat:");
      u_hat.print();

      for (let iteration = 0; iteration < r; iteration++) {
        console.log(`iteration ${iteration} ==========`);

        let c_ij = tf.softmax(b_ij);
        c_ij = c_ij.expandDims(2); // expand last dimension
        console.log("c_ij:");
        c_ij.print();

        let s_j = tf.sum(tf.mul(c_ij, u_hat), 0);
        s_j = s_j.expandDims(2);
        console.log("s_j:");
        s_j.print();

        let v_j = squash(s_j);
        console.log("v_j:" + typeof(v_j));
        v_j.print();
        console.log(v_j.shape)

        let v_j_transformed = v_j.squeeze(2).expandDims(0).broadcastTo([in_capsule_count, out_capsule_count, out_capsule_dimension]);
        console.log("v_j transformed");
        v_j_transformed.print();

        b_ij = tf.add(b_ij, tf.sum(tf.mul(u_hat, v_j_transformed), 2));
      }
    }

    function squash_old(tensor) {
      let squared_norm = tf.sum(tf.square(tensor), axis=-1, keepdims=true)
      safe_norm = tf.sqrt(squared_norm + 1e-7)
      squash_factor = squared_norm / (1. + squared_norm)
      unit_vector = input / safe_norm
      return squash_factor * unit_vector
    }

    // Squashing function for Capsule Networks
    function squash(s) {
      // Step 1: Compute the norm (Euclidean norm) of the vector along the last axis (axis=-1)
      const norm = tf.norm(s, 'euclidean', -1); // This returns a tensor of shape [batchSize] or a scalar if s is 1D
      
      // Step 2: Square the norm
      const normSquared = tf.square(norm);
      
      // Step 3: Compute the squashing factor: ||s_j||^2 / (1 + ||s_j||^2)
      const squashFactor = tf.div(normSquared, tf.add(normSquared, tf.scalar(1.0)));
      
      // Step 4: Normalize the vector s_j by dividing by its norm
      // If s is a batch of vectors, norm has shape [batchSize], so we need to expand it to shape [batchSize, 1]
      const normalizedS = tf.div(s, norm.expandDims(-1)); // Ensure broadcasting works properly
      
      // Step 5: Return the final squashed vector: squashFactor * normalizedS
      return tf.mul(squashFactor.expandDims(-1), normalizedS);
    }

    function addCapsule(vector) {
      const newDiv = document.createElement('div');
      newDiv.classList.add('newDiv');
      newDiv.textContent = vector.join(", ");
      document
          .querySelector('.container')
          .appendChild(newDiv);
    }

    function drawMatrix(matrix) {
      for (let i = 0; i < matrix.shape[0]; i++) {
        console.log(typeof(matrix.arraySync()[i]));
        addCapsule(matrix.arraySync()[i]);
      }
    }

    let u = tf.tensor([
      [1.0, 1.0],
      [2.0, 0.5],
      [1.2, 2.0]
    ])
    routing(u, 2, 2);

    drawMatrix(u);

    </script>
  </body>
</html>